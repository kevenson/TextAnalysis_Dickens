{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Analysis using TextBlob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lesson, we'll expore text analysis using [TextBlob](http://textblob.readthedocs.io/en/dev/). TextBlob is a Python library for processing textual data, which provides a simple API (*application programming interface*) for diving into common natural language processing (NLP) tasks such as part-of-speech tagging, noun phrase extraction, sentiment analysis, classification, translation, and more.\n",
    "\n",
    "*Note: a \"library\" (or \"module\") is just programming-speak for an extension. It's something we can add to our Python installation in order to get special abilities.* \n",
    "\n",
    "The process to `import` a library into your Jupyter Notebook is very simple, but in order to do so, we must first install the library on the computer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Installing TextBlob on your computer\n",
    "To [install TextBlob](http://textblob.readthedocs.io/en/dev/install.html) on your computer, open the Anaconda3 folder in the Start menu (Start -> All Programs -> Anaconda3 (64-bit)), and select the Anaconda Prompt.\n",
    "\n",
    "In the window that opens, type `pip install textblob` and hit enter. You should see the installation process and the message \"Successfully installed textblob-0.15.1\" when the installation is complete.\n",
    "\n",
    "##### Installing NLTK on your computer\n",
    "\n",
    "Now, we also need to install the NLTK corpora that we will use with TextBlob. To do this, in the Anaconda Prompt window, type: `python -m textblob.download_corpora` and hit enter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Importing TextBlob into your Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've installed TextBlob on our computer, we can start using it in our Jupyter Notebook. To do this, we first need to `import` the library:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# run the code block below to import TextBlob \n",
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that it might take a few moments for TextBlob to be imported. \n",
    "\n",
    "Now, let's test TextBlob to make sure it's working properly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "blob = TextBlob(\"It was the best of times, it was the worst of times...\")\n",
    "print(blob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This small piece of code takes a string (\"It was the...\"), and uses the TextBlob library we imported to create a special TextBlob object we have named \"blob\". \n",
    "\n",
    "Now that we know TextBlob is working, let's try using one of the built-in functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# what do you think this will do?\n",
    "\n",
    "print(blob.translate(to=\"es\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That last line of code takes our `blob` object and translates it, using the [Google Translate API](https://cloud.google.com/translate/). The free version of Google Translate is included in TextBlob. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quiz 1: In the space below write a function that takes a string as an argument and translates it into another language.\n",
    "\n",
    "Hint: you may want to refer to the documentation [here](http://textblob.readthedocs.io/en/dev/quickstart.html#translation-and-language-detection)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# add your code here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Before we dive in deeper, let's write a quick function that will make it easy to retrieve TextBlob objects based on a selected file. This will make it easier to use TextBlob to analyze the novels we have saved in our `data/` directory.\n",
    "\n",
    "Remember how to read files? Each time we had to open a file, read the contents and then close the file. Since this is a series of steps we will often need to do, we can write a single function that does all that for us. We write a small utility function read_file(filename) that reads the specified file and simply returns all contents as a TextBlob object that we can work with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_file(filename):\n",
    "    \"Read the contents of FILENAME and return as a TextBlob object.\"\n",
    "    infile = open(filename, encoding=\"utf8\")\n",
    "    contents = infile.read()\n",
    "    blob = TextBlob(contents) \n",
    "    infile.close()\n",
    "    return blob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, instead of having to open a file, read the contents and close the file, we can just call the function read_file to do all that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "text = read_file(\"data/OliverTwist.txt\")\n",
    "#print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, you might be a little confused about what we mean by \"TextBlob objects.\" Without going into too much detail, this is a feature of object-oriented-programming, where we are interacting with special data structures called *objects*. \n",
    "\n",
    "All you really need to know now is that when we talk about TextBlob objects, what we really mean are pieces of text that have been converted into a TextBlob, which means we can call the build-in TextBlob functions (or methods) on this object, as we do with the line: `blob.translate(to=\"es\")` where we call the method `translate` on the TextBlob object named `blob`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Now that we have an easy-to-use function for creating our TextBlobs, we can start learning some new functionality."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word & Noun Phrase Frequencies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TextBlob makes it easy to calculate the [frequencies of words and noun phrases](http://textblob.readthedocs.io/en/dev/quickstart.html#get-word-and-noun-phrase-frequencies) without needing to build our own functions, as we did in the previous lessons. \n",
    "\n",
    "For example, to calcuate how many times the word \"Oliver\" (case insensitive) appears in our `text` TextBlob, we can use the following line of code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# find single word count, using lowercase for our search\n",
    "text.word_counts['oliver']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">**Wait, didn't we recieve a different word count in our previous exercise?**\n",
    "Why do you think this could be?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also use the same basic functionality to retrieve frequencies of **all** words in the form of a dictionary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "text.word_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can do something similar with noun phrases:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# to find the frequency of a single noun phrase:\n",
    "text.np_counts['mr. bumble']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below will retrieve frequencies of **all** noun phrases in the form of a dictionary...note that this may take a minute or two to run!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# to retrieve the frequencies of all noun phrases as a dictionary\n",
    "\n",
    "text.np_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quiz 2: write a function that takes a list of terms and a TextBlob to search and returns a dictionary with each term as a key and the frequency of each term as the value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def word_counter(blob, mylist):\n",
    "    \"return dictionary of word frequencies\"\n",
    "    # Enter your code here:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From [Wikipedia](https://en.wikipedia.org/wiki/Sentiment_analysis): \n",
    "\n",
    "Sentiment analysis \"refers to the use of natural language processing, text analysis, computational linguistics, and biometrics to systematically identify, extract, quantify, and study affective states and subjective information...\n",
    "\n",
    "A basic task in sentiment analysis is classifying the polarity of a given text at the document, sentence, or feature/aspect level—whether the expressed opinion in a document, a sentence or an entity feature/aspect is positive, negative, or neutral.\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# What do you think this will return?\n",
    "text.sentiment\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The [sentiment](http://textblob.readthedocs.io/en/dev/api_reference.html#textblob.blob.TextBlob.sentiment) method returns two values: polarity and subjectivity. The polarity score is a float within the range [-1.0, 1.0], where -1.0 is very negative and 1.0 is very positive.\n",
    "\n",
    "The subjectivity is a float within the range [0.0, 1.0] where 0.0 is very objective and 1.0 is very subjective.\n",
    "\n",
    "Note that these values are returned in the form of a tuple, which is very similar to a list. \n",
    "\n",
    "We can also pull just the polarity or the subjectivity scores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# try running the code below\n",
    "\n",
    "print(\"The polarity is \" + str(text.sentiment[0]))\n",
    "print(\"The subjectivity is \" + str(text.sentiment[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, we print the individual polarity and subjectivity values by referring to their respective indicies and changing them to strings with the `str()` function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quiz #3: In the cell below, determine the polarity and subjectivity of at least two Dickens novels. See if you can find the most positive and most negative. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# enter your code below\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What if we want to look at individual sentences? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[TextBlob also supports tokenization](http://textblob.readthedocs.io/en/dev/quickstart.html#tokenization), or breaking a text into words or sentences. \n",
    "\n",
    "For sentence tokenization, TextBlob gives us a method called `sentences` that can be used to break a larger corpus into individual sentences. This can be used on its own, but we can also combine it with the sentiment analysis skills we've been building. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# try running the code below\n",
    "\n",
    "for sentence in text.sentences:\n",
    "    print(sentence.sentiment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay...that's a lot of information. What we've done here is use TextBlob's built-in `sentences` method to break the text up into individual sentences. These sentences are then iterated over through our `for` loop, printing the `sentiment` for each."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But what can we do with this information? Now that we have computed a range of general statistics for our text, it would be nice to have a better way to visualize them. We could for example, plot for each sentence, what its polarity is and even graph the change in sentiment over the duration of the novel.\n",
    "\n",
    "Python is quite good at graphing or plotting. This isn't something that we'll tackle here due to time constraints, but if you're interested in experimenting after class, the plotting library *matplotlib* (see [here](http://matplotlib.org)) is very well supported and allows us to produce all kinds of graphs. \n",
    "\n",
    "What we'll do instead here, is learn how to export data from Python that we can use in a 3rd party program that we may be more comfortable with, such as MS Excel or Goolge Sheets. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### Exporting Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To do this, let's first create a dictionary. This will allow us to add the polarity values of each sentence in the text to this dictionary, with the sentence number as the key and the polarity as the value. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# showing change in sentiment over the duration of the novel\n",
    "\n",
    "sentiment_polarity_by_sentence = {}\n",
    "counter = 0\n",
    "for sentence in text.sentences:\n",
    "    sentiment_polarity_by_sentence[counter] = sentence.sentiment[0]\n",
    "    counter +=1\n",
    "    \n",
    "print(sentiment_polarity_by_sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's try exporting our dictionary to a format that we can use with other programs. A `csv` file is a good option here, as it can handle tabular data of this sort well and can be used with many different types of applications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# exporting to CSV\n",
    "import csv\n",
    "\n",
    "with open('sentiment_polarity_by_sentence.csv', 'w',  newline='') as csv_file:\n",
    "    writer = csv.writer(csv_file)\n",
    "    for key, value in sentiment_polarity_by_sentence.items():\n",
    "       writer.writerow([key, value])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Don't worry too much about the syntax here. Basically what we are doing is importing a new Python library (`csv`), and using it to write our dictionary, `sentiment_polarity_by_sentence`, to a new CSV file that will be saved in the same directory as our Jupyter Notebook files. \n",
    "\n",
    "It's worth noting that with minimal alterations, you could re-use the same block of code to export word or noun phrase counts as csv files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### Graphing with Google Sheets\n",
    "\n",
    "Now, we can open this file up in our preferred application. In this example, we'll use Google Sheets. \n",
    "\n",
    "To do this, first login to your Bates Gmail account, and use the small grid menu on the upper right to open your Google Drive. \n",
    "\n",
    "Next, simply drag and drop your new CSV file into your Drive account. Once it's finished uploading, right click the file and select Open With --> Google Sheets\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you've created your new Google Sheet, highlight the two columns with our data, and select Insert--> Chart.\n",
    "\n",
    "This will give us a nice line chart that we can customize and even publish online"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "-------------\n",
    "\n",
    "## Polarity scores by novel\n",
    "\n",
    "Let's try another example. What if we wanted to plot the polarity score for each of Dicken's novels?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# First, let's create a list that contains our novels\n",
    "novels = ['ATaleOfTwoCities','BarnabyRudge','BleakHouse','DavidCopperfield','DombeyandSon','GreatExpectations','HardTimes','LittleDorrit','MartinChuzzlewit','NicholasNickleby','OliverTwist', 'OurMutualFriend', 'TheMysteryofEdwinDrood','TheOldCuriosityShop','ThePickwickPapers']\n",
    "\n",
    "# Now, let's create an empty dictionary to store our data:\n",
    "sentiment_polarity_by_novel = {}\n",
    "\n",
    "# Finally, let's iterate through our list of novels, create a TextBlob of each using our read_file function\n",
    "# and add the polarity of each to our dictionary as values\n",
    "for novel in novels:\n",
    "    newBlob = read_file(\"data/\"+novel+\".txt\")\n",
    "    #newBlob = TextBlob(novel)\n",
    "    s_score = newBlob.sentiment[1]\n",
    "    sentiment_polarity_by_novel[novel] = s_score\n",
    "\n",
    "# Just to confirm we are getting what we want:\n",
    "print(sentiment_polarity_by_novel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can use the same process as above to export this as a CSV file, and then to use that CSV file in Google Sheets to generate a data visualization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# exporting to CSV\n",
    "with open('sentiment_polarity_by_novel.csv', 'w',  newline='') as csv_file:\n",
    "    writer = csv.writer(csv_file)\n",
    "    for key, value in sentiment_polarity_by_novel.items():\n",
    "       writer.writerow([key, value])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Final Quiz\n",
    "\n",
    "User choice - use the tools and techniques we've reviewed during these lessons to generate a data visualization of your choice using at least one novel from our Dickens corpus. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
